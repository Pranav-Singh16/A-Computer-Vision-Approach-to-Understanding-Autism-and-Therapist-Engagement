{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9VYFsznzP0ok","executionInfo":{"status":"ok","timestamp":1712842833867,"user_tz":-330,"elapsed":5290,"user":{"displayName":"Pranav Singh","userId":"14921887481779284305"}}},"outputs":[],"source":["import sys\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","import signal\n","import cv2\n","from PIL import Image\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","import matplotlib.pyplot as plt\n","import torch.optim as optim\n","import torchvision.transforms as transforms"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Cb2zTi0zrD7x","executionInfo":{"status":"ok","timestamp":1712842961196,"user_tz":-330,"elapsed":127334,"user":{"displayName":"Pranav Singh","userId":"14921887481779284305"}}},"outputs":[],"source":["frames = []\n","\n","def extract_frames(video_path, interval_seconds):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(\"Error: Could not open video file:\", video_path)\n","        return []\n","\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    interval_frames = int(fps * interval_seconds)\n","    frame_count = 0\n","    extracted_frames = []\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        frame_count += 1\n","        if frame_count % interval_frames == 0:\n","            extracted_frames.append(frame)\n","\n","    cap.release()\n","    return extracted_frames\n","\n","for i in range(1, 9):  # Corrected the range to iterate from 1 to 9\n","    video_path = '/content/drive/MyDrive/Internshala/Videos/'+str(i)+'.mp4'\n","    interval_seconds = 10\n","\n","    extracted_frames = extract_frames(video_path, interval_seconds)\n","    frames.extend(extracted_frames)\n","\n","frames_array = np.array(frames)"]},{"cell_type":"code","source":["images_edge = []  # Creating an empty list to store edge images\n","for i in range(len(frames)):\n","  gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n","  blurred = cv2.GaussianBlur(gray, (5,5), 0)\n","  edges = cv2.Canny(blurred, 30, 80)\n","  images_edge.append(edges)  # Appending each edge image to the list\n","\n","images_edge = np.array(images_edge)\n","len(images_edge)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6XZRd0TVZ5r","executionInfo":{"status":"ok","timestamp":1712843005861,"user_tz":-330,"elapsed":795,"user":{"displayName":"Pranav Singh","userId":"14921887481779284305"}},"outputId":"bc75f8d0-7046-4b40-e4a9-f390c1f2772f"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["387"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Read the CSV file where data is stored for training\n","df = pd.read_csv('/content/drive/MyDrive/internship.csv')\n","\n","# Split the data into training, cross-validation, and test sets\n","images_train = images_edge[0:235]  # Assuming the first column contains image paths\n","labels_train = df.iloc[1:236, 1:].values  # Convert DataFrame to numpy array\n","images_cv = images_edge[235:315]  # Assuming the first column contains image paths\n","labels_cv = df.iloc[236:316, 1:].values  # Convert DataFrame to numpy array\n","images_test = images_edge[315:]  # Assuming the first column contains image paths\n","labels_test = df.iloc[316:388, 1:].values  # Convert DataFrame to numpy array\n","\n","# Convert your data to PyTorch tensors\n","images_tensor_train = torch.tensor(images_train)  # Convert image data to PyTorch tensor\n","labels_tensor_train = torch.tensor(labels_train)  # Convert additional features data to PyTorch tensor\n","images_tensor_cv = torch.tensor(images_cv)  # Convert image data to PyTorch tensor\n","labels_tensor_cv = torch.tensor(labels_cv)  # Convert additional features data to PyTorch tensor\n","images_tensor_test = torch.tensor(images_test)  # Convert image data to PyTorch tensor\n","labels_tensor_test = torch.tensor(labels_test)  # Convert additional features data to PyTorch tensor\n","\n","print(len(images_train), len(images_cv), len(images_test))\n","print(len(labels_train), len(labels_cv), len(labels_test))\n","# Create a combined dataset if needed\n","# For example, if you want to combine image data and additional features data:\n","combined_dataset_train = torch.utils.data.TensorDataset(images_tensor_train, labels_tensor_train)\n","combined_dataset_cv = torch.utils.data.TensorDataset(images_tensor_cv, labels_tensor_cv)\n","combined_dataset_test = torch.utils.data.TensorDataset(images_tensor_test, labels_tensor_test)"],"metadata":{"id":"4h8rMsb5PLVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the custom model\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # Updated in_channels to 1 for grayscale images\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.output_branch1 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),  # Adjusted to match the size of the flattened feature map\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","        self.output_branch2 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),  # Adjusted to match the size of the flattened feature map\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","        self.output_branch3 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),  # Adjusted to match the size of the flattened feature map\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","        self.output_branch4 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),  # Adjusted to match the size of the flattened feature map\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        print(\"Size of feature map before flattening:\", x.size())  # Add this line for debugging\n","        x = torch.flatten(x, 1)\n","        print(\"Size of flattened feature map:\", x.size())  # Add this line for debugging\n","        out1 = self.output_branch1(x)\n","        out2 = self.output_branch2(x)\n","        out3 = self.output_branch3(x)\n","        out4 = self.output_branch4(x)\n","        return out1, out2, out3, out4\n","\n","\n","# Assuming you have input image data (images_train) and corresponding labels\n","# Convert your data to PyTorch tensors\n","images_tensor = torch.tensor(images_train).float().unsqueeze(1)  # Convert grayscale images to PyTorch tensor and make it float\n","labels_tensor = torch.tensor(labels_train).long()  # Convert labels to PyTorch tensor and ensure it's a long tensor\n","\n","# Create a combined dataset\n","combined_dataset = TensorDataset(images_tensor, labels_tensor)\n","\n","# Create a data loader\n","train_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n","\n","# Instantiate the model\n","model = CustomModel()\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 30\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs1, outputs2, outputs3, outputs4 = model(inputs)\n","        loss1 = criterion(outputs1, labels[:, 0])  # Adjusted to select the appropriate target for each output branch\n","        loss2 = criterion(outputs2, labels[:, 1])  # Adjusted to select the appropriate target for each output branch\n","        loss3 = criterion(outputs3, labels[:, 2])  # Adjusted to select the appropriate target for each output branch\n","        loss4 = criterion(outputs4, labels[:, 3])  # Adjusted to select the appropriate target for each output branch\n","        total_loss = loss1 + loss2 + loss3 + loss4\n","\n","        # Backward pass and optimize\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        # Print statistics\n","        running_loss += total_loss.item()\n","        if i % 10 == 9:  # Print every 10 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 10))\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","\n","# Save the model's state dictionary\n","# torch.save(model.state_dict(), 'custom_model_weights.pth')\n","\n","\n","# Define the file path where you want to save the model weights\n","file_path = '/content/drive/MyDrive/Colab Notebooks/contweights.pth'\n","\n","# Save the model's state dictionary at the specified file path\n","torch.save(model.state_dict(), file_path)"],"metadata":{"id":"Ayp7QOjylwKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the custom model class\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","        self.output_branch1 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","        self.output_branch2 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","        self.output_branch3 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","        self.output_branch4 = nn.Sequential(\n","            nn.Linear(256 * 11 * 20, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 3)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = torch.flatten(x, 1)\n","        out1 = self.output_branch1(x)\n","        out2 = self.output_branch2(x)\n","        out3 = self.output_branch3(x)\n","        out4 = self.output_branch4(x)\n","        return out1, out2, out3, out4\n","\n","# Assuming you have input images (images_test)\n","images_tensor = torch.tensor(images_test).float().unsqueeze(1)  # Convert grayscale images to PyTorch tensor and make it float\n","\n","# Define the dataset and data loader for prediction\n","val_dataset = TensorDataset(images_tensor)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# Load the trained model\n","model = CustomModel()\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/contweights.pth'))\n","model.eval()  # Set the model to evaluation mode\n","\n","# Make predictions on the test dataset\n","predictions = []\n","with torch.no_grad():\n","    for batch_data in val_loader:\n","        # Get inputs from the current batch\n","        inputs = batch_data[0]\n","\n","        # Forward pass\n","        outputs1, outputs2, outputs3, outputs4 = model(inputs)\n","        preds1 = torch.argmax(outputs1, dim=1)\n","        preds2 = torch.argmax(outputs2, dim=1)\n","        preds3 = torch.argmax(outputs3, dim=1)\n","        preds4 = torch.argmax(outputs4, dim=1)\n","        batch_preds = torch.stack((preds1, preds2, preds3, preds4), dim=1)\n","        predictions.append(batch_preds)\n","\n","# Convert predictions to a numpy array\n","predictions = torch.cat(predictions).numpy()\n","\n","# Display predictions\n","print(predictions)"],"metadata":{"id":"yf_36-SKPVOv"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1V6tYRTvNd-kAkLtw7W-Hj6mBaRdW2EhM","authorship_tag":"ABX9TyPCPmPKwkmKI2nd/uDDpMYz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}